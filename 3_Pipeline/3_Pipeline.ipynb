{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8489545f-5d3d-4a0a-91e9-8ec9091967bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea81b30e-b5a4-4bc6-b260-e80e66773583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy library, which is used for natural language processing.\n",
    "nlp = spacy.blank('en')\n",
    "doc = nlp(\" Employee receives 100$ tip. Then he said thank you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0334fb7d-a860-4a56-a680-dd7394f64366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Employee\n",
      "receives\n",
      "100\n",
      "$\n",
      "tip\n",
      ".\n",
      "Then\n",
      "he\n",
      "said\n",
      "thank\n",
      "you\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Process the text with the blank model, creating a 'doc' object that contains tokens.\n",
    "for token in doc:\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0a96d6-b564-4b6c-bcc7-ae5eedebc7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipe is empty or blanck\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f5f357-4614-49a6-9f10-34112f320af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9382a4ee-963c-45b8-8faf-9db12f505906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x71d7e0339480>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x71d7e03397e0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x71d7e3f538b0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x71d7e058cc80>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x71d7e0350ac0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x71d7e3f537d0>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f82b0bd1-b188-4d26-b4ba-5d421bcb2b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the names of the pipeline components in the loaded model. This will include 'tagger', 'parser', and 'ner'.\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40773a5-19a2-4599-8e87-3e84ad0e0868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee  |  NOUN  |  employee\n",
      "receives  |  VERB  |  receive\n",
      "100  |  NUM  |  100\n",
      "$  |  NUM  |  $\n",
      "tip  |  NOUN  |  tip\n",
      ".  |  PUNCT  |  .\n",
      "Then  |  ADV  |  then\n",
      "he  |  PRON  |  he\n",
      "said  |  VERB  |  say\n",
      "thank  |  VERB  |  thank\n",
      "you  |  PRON  |  you\n",
      ".  |  PUNCT  |  .\n"
     ]
    }
   ],
   "source": [
    "text = \"Employee receives 100$ tip. Then he said thank you.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "\"\"\"\n",
    "# Iterate over each token in the 'doc' and print the token,\n",
    "its part of speech (POS) tag, and its lemma.\n",
    "# 'token.pos_' provides the POS tag, and 'token.lemma_'\n",
    "provides the lemma (base form) of the token.\n",
    "\"\"\"\n",
    "for token in doc:\n",
    "  print(token, \" | \", token.pos_, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f15db4-382c-4cb6-9eda-5ebfade15008",
   "metadata": {},
   "source": [
    "## How to use French language using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03682596-7357-4d68-b78b-657a8b38fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the French small model\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32bc92f-1961-4872-a11a-503a79845084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employer  |  PROPN  |  Employer\n",
      "reçoit  |  VERB  |  recevoir\n",
      "100  |  NUM  |  100\n",
      "$  |  NOUN  |  dollar\n",
      "de  |  ADP  |  de\n",
      "pourboire  |  NOUN  |  pourboire\n",
      ".  |  PUNCT  |  .\n",
      "Et  |  CCONJ  |  et\n",
      "il  |  PRON  |  il\n",
      "dit  |  VERB  |  dire\n",
      "merci  |  NOUN  |  merci\n",
      ".  |  PUNCT  |  .\n"
     ]
    }
   ],
   "source": [
    "# Process the text with the loaded model\n",
    "doc = nlp(\"Employer reçoit 100$ de pourboire. Et il dit merci.\")\n",
    "\n",
    "# Iterate over each token in the doc and print the token, its POS tag, and its lemma\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.pos_, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5e9ea-58c3-4e0c-895b-01eb3ca10cd0",
   "metadata": {},
   "source": [
    "## Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01051734-35a5-48cc-a386-631c7f03ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "buying U.K. startup for  |  MISC  |  Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "John Doe  |  PER  |  Named person or family.\n",
      "confirmed this on Monday  |  PER  |  Named person or family.\n"
     ]
    }
   ],
   "source": [
    "# Process the text\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion. John Doe, the CEO, confirmed this on Monday.\")\n",
    "\n",
    "# Iterate over the named entities in the doc\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac106d-a70e-46b8-a7c4-26b76cf2fa26",
   "metadata": {},
   "source": [
    "## Named Entity Recognition, or NER for short\n",
    "\n",
    "It is a subtask of NLP that focuses on identifying and classifying entities within textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b52e73-c439-4eec-8ce5-06c493850172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER component is present in the pipeline.\n",
      "Apple  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "buying U.K. startup for  |  MISC  |  Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "John Doe  |  PER  |  Named person or family.\n",
      "confirmed this on Monday  |  PER  |  Named person or family.\n"
     ]
    }
   ],
   "source": [
    "# Ensure that the NER component is in the pipeline\n",
    "if 'ner' in nlp.pipe_names:\n",
    "    print(\"NER component is present in the pipeline.\")\n",
    "\n",
    "# Iterate over the named entities in the doc\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6db896-8e76-43f2-921f-ec8a472f8483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
